{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46641832-d8a9-42a4-9722-2ee4f48e3a3d",
   "metadata": {},
   "source": [
    "# Hawthorne Media Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95dbab-c4fe-4bc9-9961-fe00b805bf51",
   "metadata": {},
   "source": [
    "This program ingests short-form media and analyzes the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761164d-9362-4d5b-ba96-c2e58bd36b25",
   "metadata": {},
   "source": [
    "### Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6ce3d-00d8-4567-a000-e83e27b4d4dd",
   "metadata": {},
   "source": [
    "Setup<br>\n",
    "Data Management<br>\n",
    "Audio Transcription<br>\n",
    "Video sampling<br>\n",
    "Analysis<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e86f6-e1d8-4430-ba9f-92be5e25f1d3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fe8ad-9034-4e6f-afb8-2fd2f914504a",
   "metadata": {},
   "source": [
    "We recommend using a designated environment for this program. See the README file for instructions on preparing the enviornment. Package installations are controlled via the requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e174881-0785-4066-bbdc-cb2e8c19a687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using Anaconda, uncomment and run this code.\n",
    "# conda install -c conda-forge libsndfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a50b0a-3195-40db-9ecf-04ec0752a30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#$ conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56305479-c155-4588-b41d-51d04f71d95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The ffmpeg package is included in the folder. Alternatively you may download FFmpeg from the official site: https://ffmpeg.org/download.html, extract it, and update the path to the folder where you placed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f345e6-924c-483f-b219-efb8469ddbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\envs\\Media_Analyzer_Env\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "C:\\Users\\matth\\anaconda3\\envs\\Media_Analyzer_Env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Package imports:\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "import tempfile\n",
    "# import streamlit as st\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled # Replace with other transcription package\n",
    "import yt_dlp\n",
    "import openai\n",
    "import tiktoken\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7439b4cb-d969-41d9-9e21-939af14984da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Desktop\\MSBA\\Capstone Project\\ffmpeg-7.1.1-full_build\\bin\n"
     ]
    }
   ],
   "source": [
    "with open('ffmpegPath.txt', 'r') as file:\n",
    "    ffmpeg_path = file.read()\n",
    "    print(ffmpeg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2295aa35-179a-40e0-b0a2-7cef93550ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ffmpeg to PATH manually\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b91ba3-0308-4650-98b7-687f17b20398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AudioSegment.converter = ffmpeg_path + r\"\\ffmpeg.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b38266-cacd-45b4-98ea-027d9e9d4922",
   "metadata": {},
   "source": [
    "### Setting up your API Key\n",
    "This program uses an openai API. You will need a key to access the API. This key is linked to the organization's account and API calls will be charged against the account. To protect the key, we recommend storing it as an environmental variable using the steps below. This step only needs to be done once for the computer or environment in which you are working; you never need repeat this step unless you set up a new account with the LLM. Note that the name of the key is case sensitive and must match exactly.<br><br>\n",
    "\n",
    "##### If you use Anaconda:\n",
    "&emsp; Launch Anaconda Prompt (this is different than the Windows command prompt)<br>\n",
    "&emsp; run: conda active base <br>\n",
    "&emsp; then run: setx AI_API_Key \"your_API_Key\"<br>\n",
    "\n",
    "##### For Windows:\n",
    "&emsp; From the Windows start menu, select \"Settings\" <br>\n",
    "&emsp; Go to \"System\" \\> \"Advanced System Settings\" <br>\n",
    "&emsp; From the \"Advanced\" tab, select the \"Evironmental Variables\" button <br>\n",
    "&emsp; Select \"New\" <br>\n",
    "&emsp; Name the variable \"AI_API_Key\" <br>\n",
    "&emsp; Enter the key as the variable value; click \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc45f74-831e-4cae-8cd0-74075a92083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User-provided OpenAI API Key via file upload or text input ---\n",
    "api_key = os.environ.get('AI_API_Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e9cda4-9f54-4663-b964-9b513c37e647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c58cc0c5-96f9-426a-a24a-bd653202b57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uncomment for troubleshooting API key errors\n",
    "# print(api_key)\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c9d97-630f-4f4c-8cd3-d1cffb293a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Alternate method\n",
    "uploaded_file = st.file_uploader(\n",
    "    label=\"Upload a .txt file containing your OpenAI API key:\",\n",
    "    type=[\"txt\"],\n",
    "    help=\"File should contain only the API key text.\"\n",
    ")\n",
    "if uploaded_file:\n",
    "    try:\n",
    "        api_key = uploaded_file.read().decode(\"utf-8\").strip()\n",
    "    except Exception:\n",
    "        st.error(\"Failed to read API key from the uploaded file.\")\n",
    "if not api_key:\n",
    "    api_key = st.text_input(\n",
    "        \"Or enter your OpenAI API key manually:\",\n",
    "        type=\"password\"\n",
    "    ).strip() or None\n",
    "if not api_key:\n",
    "    st.warning(\"Please provide your OpenAI API key by upload or manual entry to proceed.\")\n",
    "    st.stop()\n",
    "\n",
    "##### Set the OpenAI key for the library and API\n",
    "openai.api_key = api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f803b-d56c-4156-987c-6077aa6623fe",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b5557-3010-451c-8e64-79b537bf1aca",
   "metadata": {},
   "source": [
    "In this section, we ingest the media from a list and set up a dataframe to store the dimension values generated during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1822fd8b-6c99-434e-b398-bb33d5e0b733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the list of creatives to analyze\n",
    "media_list = pd.read_csv(\"WindowNation_Pathmatics_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a84ba8-86ba-48de-a0b1-36906ef20bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Advertiser                                       Andersen Corporation\n",
       "Date                                                         1/1/2025\n",
       "Device                                                  Desktop Video\n",
       "Type                                                            Video\n",
       "First Seen                                                  7/17/2023\n",
       "Last Seen                                                    1/9/2025\n",
       "Link to Creative    https://s3.amazonaws.com/YM_Ads/RWQy_qJW4LArer...\n",
       "Spend                                                        309.5686\n",
       "Impressions                                                     62594\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a specific creative from the list.\n",
    "# Internal team note: Replace this with a loop for batch processing later in the project.\n",
    "media_list.loc[6,] # choose a video from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f748e1-4cd2-41f1-9eb4-906c9ca162dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_url = media_list.loc[6,'Link to Creative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581ab037-c88b-4de3-a5e5-78853cbcf5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/YM_Ads/RWQy_qJW4LArera54bPNtg.mp4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url # (optional) check that the url has been correctly identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32d362-960b-41c9-ac47-9dd6de560224",
   "metadata": {},
   "source": [
    "## Audio Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71102e0d-9e52-426e-84df-fb2aa68a4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step downloads the audio from the creative.\n",
    "\n",
    "def download_audio(video_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Use yt-dlp to download the best audio stream to a local file.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': 'audio.%(ext)s'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(video_url, download=True)\n",
    "        filename = ydl.prepare_filename(info)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121097b9-fb39-4ad0-ab7b-d642ff91d94d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[generic] Extracting URL: https://s3.amazonaws.com/YM_Ads/RWQy_qJW4LArera54bPNtg.mp4\n",
      "[generic] RWQy_qJW4LArera54bPNtg: Downloading webpage\n",
      "[info] RWQy_qJW4LArera54bPNtg: Downloading 1 format(s): mp4\n",
      "[download] Destination: audio.mp4\n",
      "[download] 100% of    3.71MiB in 00:00:07 at 526.63KiB/s   \n"
     ]
    }
   ],
   "source": [
    "raw_audio_path = download_audio(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c9a4fd-cbd2-4f27-b714-f586f1856d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert file to wav\n",
    "\n",
    "def convert_to_wav(audio_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert any audio file (mp4/m4a/webm) to WAV (mono, 16kHz) for transcription.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "\n",
    "    wav_path = os.path.join(tempfile.gettempdir(), \"audio.wav\")\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "    os.remove(audio_path)\n",
    "    return wav_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04dfcc50-33ee-4c8b-b995-417b6b28ae22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_path = convert_to_wav(raw_audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c235e78-54cd-4dba-921c-208c32ceba0d",
   "metadata": {},
   "source": [
    "#### Alternate to pydub, (conversion to wav)\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def convert_to_wav(audio_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert any audio file (mp4/m4a/webm) to WAV (mono, 16kHz) for transcription.\n",
    "    \"\"\"\n",
    "    wav_path = \"audio.wav\"\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\", \"-y\", \"-i\", audio_path,\n",
    "        \"-ac\", \"1\", \"-ar\", \"16000\", wav_path\n",
    "    ], check=True)\n",
    "    os.remove(audio_path)\n",
    "    return wav_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d5efb-8a24-40fe-ad8f-cb5fe7800447",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Alternate to TorchAudio (for transcription)\n",
    "def transcribe_with_openai(wav_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Use OpenAI Whisper API to transcribe the given WAV audio file.\n",
    "    \"\"\"\n",
    "    # Open file in binary mode\n",
    "    with open(wav_path, \"rb\") as audio_file:\n",
    "        transcription = openai.Audio.transcribe(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    os.remove(wav_path)\n",
    "    return transcription[\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d562e17-29c1-4279-8f15-d3d158089c08",
   "metadata": {
    "tags": []
   },
   "source": [
    "transcribe_with_openai(\"C:\\\\Users\\\\ttesno\\\\AppData\\\\Local\\\\Temp\\\\audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206ac462-452b-4ed3-ab79-e59e00b3d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription with torchaudio and Wav2Vec\n",
    "\n",
    "def transcribe_with_torchaudio(wav_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe a WAV audio file using torchaudio and a pretrained Wav2Vec2 model.\n",
    "    \"\"\"\n",
    "    # Load pretrained model and processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "    # Load audio\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "\n",
    "    # Resample if needed\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Preprocess\n",
    "    input_values = processor(waveform.squeeze().numpy(), return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.decode(predicted_ids[0])\n",
    "    \n",
    "    # Clean up\n",
    "    os.remove(wav_path)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431e9744-b94f-4bfb-aa70-c5740a19480f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "transcript = transcribe_with_torchaudio(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5370311-5d81-4ea3-9b3f-fe7a40c82794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRANSFORM YOUR HOME WITH REPLACEMENT WINDOWS FROM RUNOLBAI ANDERSAN BEAUTIFUL NEW WINDOWS BRIGHTEN ANY ROOM AND REDUCE EETING AND COOLING CAUSE THEIR GORGEOUS ENERGY EFFICIENT AND HAVE UNMATCHED YOUR ABILITY RUNOLBI ANDERSON A BETTER WAY TO A BETTER WINDOW'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98142e4-4118-4f93-992e-416acbae3b3e",
   "metadata": {},
   "source": [
    "#### Chunking and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c360153e-9a68-4053-bca4-625a3d508a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_transcript(text: str, size: int = 1000, overlap: int = 200) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split transcript into overlapping chunks for embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "\n",
    "def build_faiss_index(chunks: list[str]) -> FAISS:\n",
    "    \"\"\"\n",
    "    Create a FAISS index from text chunks using OpenAI embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "\n",
    "def make_qa_chain(store: FAISS) -> RetrievalQA:\n",
    "    \"\"\"\n",
    "    Build a RetrievalQA chain for question-answering over the vector store.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    )\n",
    "\n",
    "\n",
    "def make_summary_chain():\n",
    "    \"\"\"\n",
    "    Build a summarization chain (map-reduce style).\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return load_summarize_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "226407ae-3582-4fc4-85ca-6e1ab31f2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdaabbaf-8985-422b-aada-048c5653555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = build_faiss_index(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b55cffec-55c5-485c-ac48-c182a318075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = make_qa_chain(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "284c8af5-f8e4-443e-b9cc-4563fc77512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is this ad problem-oriented or solution-oriented? Choose from Problem or Solution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591081e-311b-40a9-b2b7-cff659fb5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a22584-43b2-43d6-a09c-c12428eb751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "chunks = chunk_transcript(transcript)\n",
    "store = build_faiss_index(chunks)\n",
    "qa_chain = make_qa_chain(store)\n",
    "#summary_chain = make_summary_chain()\n",
    "\n",
    "#summary = summary_chain.run([Document(page_content=c) for c in chunks])\n",
    "\n",
    "question = \"Is this ad problem-oriented or solution-oriented? Choose from Problem or Solution\"\n",
    "answer = qa_chain.invoke(question)\n",
    "answer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbb804-b1ee-4274-a769-8b416634c4df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Media_Analyzer)",
   "language": "python",
   "name": "media_analyzer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
